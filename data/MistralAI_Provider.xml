<?xml version="1.0" encoding="UTF-8"?>
<simplicite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.simplicite.fr/base" xsi:schemaLocation="http://www.simplicite.fr/base https://www.simplicite.io/resources/schemas/base.xsd">
<object>
	<name>AIProvider</name>
	<action>upsert</action>
	<data>
		<aiPrvProvider>Mistral AI</aiPrvProvider>
		<aiPrvDefaultUrl><![CDATA[https://api.mistral.ai/]]></aiPrvDefaultUrl>
		<aiPrvDataModel><![CDATA[{}]]></aiPrvDataModel>
		<aiPrvModelsUrl><![CDATA[https://api.mistral.ai/v1/models]]></aiPrvModelsUrl>
		<aiPrvHelp><![CDATA[### Finding Your API Key

**Sign In to Mistral AI:**
- Go to the [Mistral AI website](https://console.mistral.ai/) and sign in with your credentials.

**Access API Keys:**
- Navigate to the [API keys section](https://console.mistral.ai/api-keys/) on your dashboard.
- Generate a new API key if you don't have one, or copy your existing API key.

---

### Default Endpoints

For standard deployments, use the following endpoints:


**Models Endpoint:**
- **URL:** `https://api.mistral.ai/v1/models`
- **Purpose:** Retrieve a list of available AI models.

**Completion Endpoint:**
- **URL:** `https://api.mistral.ai/v1/chat/completions`
- **Purpose:** Generate text based on a given prompt.

**Ping Endpoint:**
- **URL:** `https://api.mistral.ai/v1/models`
- **Purpose:** This endpoint is used to check the availability of the Mistral AI server. Note that Mistral AI doesn't provide a specific ping endpoint. We use the models endpoint to check credentials, but it does not verify the availability of tokens or remaining usage limits. It primarily checks server availability.


### Security Tips

- **Keep Your API Key Secure:** Do not expose your API key in client-side code or public repositories.
- **Rotate API Keys Regularly:** Periodically change your API key to enhance security.
- **Monitor Usage:** Keep track of your [API usage](https://console.mistral.ai/usage/) to ensure you stay within your usage limits.
- **Set Limits for Projects:** Define usage limits and quotas for using the API to prevent unexpected usage spikes and ensure budget control.]]></aiPrvHelp>
		<aiPrvCompletionUrl><![CDATA[https://api.mistral.ai/v1/chat/completions]]></aiPrvCompletionUrl>
		<aiPrvPingUrl><![CDATA[https://api.mistral.ai/v1/models]]></aiPrvPingUrl>
		<aiPrvSttUrl/>
		<aiPrvUserParameters><![CDATA[{
    "top_p": {
        "help": {
            "FRA": "Utilise la méthode de filtrage par noyau. Un top_p de 0.9 signifie que le modèle choisira parmi les mots qui composent 90% de la probabilité cumulée.Il est généralement recommandé de modifier soit le top p, soit la température, mais pas les deux.",
            "ENU": "Uses nucleus sampling. A top_p of 0.9 means the model will choose from the words that make up 90% of the cumulative probability. We generally recommend altering this or temperature but not both"
        },
        "default": "",
        "min": 0,
        "max": 1,
        "label": {
            "FRA": "Top p",
            "ENU": "Top p"
        }
    },
    "frequency_penalty": {
        "help": {
            "FRA": "Diminue la probabilité que le modèle génère des mots déjà utilisés dans la conversation.",
            "ENU": "Decreases the likelihood that the model will generate words that have already been used in the conversation."
        },
        "default": 0,
        "min": -1.5,
        "max": 1.5,
        "label": {
            "FRA": "Pénalité de fréquence",
            "ENU": "Frequency penalty"
        }
    },
    "presence_penalty": {
        "help": {
            "FRA": "Augmente la probabilité que le modèle évite de répéter des phrases ou des concepts déjà mentionnés dans la conversation.",
            "ENU": "Increases the likelihood that the model will avoid repeating phrases or concepts already mentioned in the conversation."
        },
        "default": 0,
        "min": -1.5,
        "max": 1.5,
        "label": {
            "FRA": "Pénalité de présence",
            "ENU": "Presence penalty"
        }
    },
    "temperature": {
        "help": {
            "FRA": "Contrôle la créativité des réponses. Une température plus élevée (ex. 1.0) rend les réponses plus variées, tandis qu'une température plus basse (ex. 0.2) les rend plus déterministes.",
            "ENU": "Controls the creativity of the responses. A higher temperature (e.g., 1.0) makes responses more varied, while a lower temperature (e.g., 0.2) makes them more deterministic."
        },
        "default": 1,
        "min": -1.5,
        "max": 1.5,
        "label": {
            "FRA": "Température",
            "ENU": "Temperature"
        }
    }
}]]></aiPrvUserParameters>
	</data>
</object>
</simplicite>
